{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(path_to_file, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RNN Character will actually learn the structure of the text from William Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '\\n')\n",
      "(1, ' ')\n",
      "(2, '!')\n",
      "(3, '\"')\n",
      "(4, '&')\n",
      "(5, \"'\")\n",
      "(6, '(')\n",
      "(7, ')')\n",
      "(8, ',')\n",
      "(9, '-')\n",
      "(10, '.')\n",
      "(11, '0')\n",
      "(12, '1')\n",
      "(13, '2')\n",
      "(14, '3')\n",
      "(15, '4')\n",
      "(16, '5')\n",
      "(17, '6')\n",
      "(18, '7')\n",
      "(19, '8')\n",
      "(20, '9')\n",
      "(21, ':')\n",
      "(22, ';')\n",
      "(23, '<')\n",
      "(24, '>')\n",
      "(25, '?')\n",
      "(26, 'A')\n",
      "(27, 'B')\n",
      "(28, 'C')\n",
      "(29, 'D')\n",
      "(30, 'E')\n",
      "(31, 'F')\n",
      "(32, 'G')\n",
      "(33, 'H')\n",
      "(34, 'I')\n",
      "(35, 'J')\n",
      "(36, 'K')\n",
      "(37, 'L')\n",
      "(38, 'M')\n",
      "(39, 'N')\n",
      "(40, 'O')\n",
      "(41, 'P')\n",
      "(42, 'Q')\n",
      "(43, 'R')\n",
      "(44, 'S')\n",
      "(45, 'T')\n",
      "(46, 'U')\n",
      "(47, 'V')\n",
      "(48, 'W')\n",
      "(49, 'X')\n",
      "(50, 'Y')\n",
      "(51, 'Z')\n",
      "(52, '[')\n",
      "(53, ']')\n",
      "(54, '_')\n",
      "(55, '`')\n",
      "(56, 'a')\n",
      "(57, 'b')\n",
      "(58, 'c')\n",
      "(59, 'd')\n",
      "(60, 'e')\n",
      "(61, 'f')\n",
      "(62, 'g')\n",
      "(63, 'h')\n",
      "(64, 'i')\n",
      "(65, 'j')\n",
      "(66, 'k')\n",
      "(67, 'l')\n",
      "(68, 'm')\n",
      "(69, 'n')\n",
      "(70, 'o')\n",
      "(71, 'p')\n",
      "(72, 'q')\n",
      "(73, 'r')\n",
      "(74, 's')\n",
      "(75, 't')\n",
      "(76, 'u')\n",
      "(77, 'v')\n",
      "(78, 'w')\n",
      "(79, 'x')\n",
      "(80, 'y')\n",
      "(81, 'z')\n",
      "(82, '|')\n",
      "(83, '}')\n"
     ]
    }
   ],
   "source": [
    "for pair in enumerate(vocab):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ind = {char:ind for ind,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'`'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5445609,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = \"From fairest creatures we desire increase\"\n",
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 lines to understand structure\n",
    "lines = '''\n",
    "From fairest creatures we desire increase,\n",
    "  That thereby beauty's rose might never die,\n",
    "  But as the riper should by time decease,\n",
    "  '''\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_seq = len(text) // (seq_len+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40041"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in char_dataset.take(500):\n",
    "#     print(ind_to_char[item.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1] #Hello my nam\n",
    "    target_txt = seq[1:] #ello my name\n",
    "    return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75\n",
      "  1 56 74  1 75 63 60  1 73 64 71 60 73  1 74]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper s\n",
      "\n",
      "\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1\n",
      " 56 74  1 75 63 60  1 73 64 71 60 73  1 74 63]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper sh\n"
     ]
    }
   ],
   "source": [
    "for input_txt, target_txt in dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[input_txt.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "buffer_size = 10000\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 135), (128, 135)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_neurons = 1026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true, y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embed_dim, batch_input_shape=[batch_size, None]))\n",
    "    model.add(GRU(rnn_neurons, return_sequences=True,\n",
    "                 stateful=True, recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 64)           5376      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1026)         3361176   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 84)           86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size=vocab_size,\n",
    "                    embed_dim=embed_dim,\n",
    "                    rnn_neurons = rnn_neurons,\n",
    "                    batch_size = batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(135, 84), dtype=float32, numpy=\n",
       "array([[ 5.7929032e-04, -2.2664322e-03,  4.6816729e-03, ...,\n",
       "        -2.9412957e-03, -7.3828886e-04, -8.1398450e-03],\n",
       "       [-2.0599971e-03, -7.4405894e-03,  9.8912120e-03, ...,\n",
       "        -2.8964311e-03,  2.9725330e-03, -4.4526919e-03],\n",
       "       [-2.3784360e-04, -1.0696603e-03,  1.1600534e-02, ...,\n",
       "        -2.5966740e-03, -5.6503941e-03, -4.8050075e-05],\n",
       "       ...,\n",
       "       [-5.6173243e-03, -2.9784967e-03,  5.4900460e-03, ...,\n",
       "        -1.0963663e-03, -3.9545069e-03,  2.8088181e-03],\n",
       "       [-4.8153857e-03, -8.7872045e-03,  1.0076446e-02, ...,\n",
       "        -1.6786165e-03,  1.0298826e-03,  2.0040581e-03],\n",
       "       [-1.6217739e-03, -2.0678081e-03,  1.1527120e-02, ...,\n",
       "        -1.7190730e-03, -6.9997516e-03,  3.5737138e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilities of each character\n",
    "example_batch_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_indices = tf.squeeze(samples_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 53, 49, 43, 43,  8, 54, 47, 74,  1, 83, 25,  7,  4, 58, 40, 44,\n",
       "       64, 56, 27, 79, 32, 61, 40, 41, 39, 14, 77,  8,  7, 41, 68, 70, 62,\n",
       "       44, 62, 52, 82, 78, 39, 31, 15, 82, 71, 51, 60, 36, 14,  9, 45, 26,\n",
       "        8, 60, 53, 45, 33, 41, 19, 21, 16, 57, 79, 46, 46, 59, 24, 35, 66,\n",
       "       78, 56, 36, 79, 10, 79, 75, 46, 51, 45,  5,  8, 71, 45, 54, 57, 12,\n",
       "       45, 47, 27,  1, 28,  8, 34, 73, 66, 37, 18, 81, 73, 66, 81, 28, 37,\n",
       "        6, 61, 14, 14, 63, 12,  9, 36, 10, 31,  0, 46, 23, 55, 50, 50, 79,\n",
       "       20, 28, 23, 77, 39, 19, 82, 81, 26, 13,  6, 43, 39, 39, 49,  3],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([':', ']', 'X', 'R', 'R', ',', '_', 'V', 's', ' ', '}', '?', ')',\n",
       "       '&', 'c', 'O', 'S', 'i', 'a', 'B', 'x', 'G', 'f', 'O', 'P', 'N',\n",
       "       '3', 'v', ',', ')', 'P', 'm', 'o', 'g', 'S', 'g', '[', '|', 'w',\n",
       "       'N', 'F', '4', '|', 'p', 'Z', 'e', 'K', '3', '-', 'T', 'A', ',',\n",
       "       'e', ']', 'T', 'H', 'P', '8', ':', '5', 'b', 'x', 'U', 'U', 'd',\n",
       "       '>', 'J', 'k', 'w', 'a', 'K', 'x', '.', 'x', 't', 'U', 'Z', 'T',\n",
       "       \"'\", ',', 'p', 'T', '_', 'b', '1', 'T', 'V', 'B', ' ', 'C', ',',\n",
       "       'I', 'r', 'k', 'L', '7', 'z', 'r', 'k', 'z', 'C', 'L', '(', 'f',\n",
       "       '3', '3', 'h', '1', '-', 'K', '.', 'F', '\\n', 'U', '<', '`', 'Y',\n",
       "       'Y', 'x', '9', 'C', '<', 'v', 'N', '8', '|', 'z', 'A', '2', '(',\n",
       "       'R', 'N', 'N', 'X', '\"'], dtype='<U1')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[samples_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 312 steps\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - 53s 168ms/step - loss: 2.6194\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - 52s 166ms/step - loss: 1.8566\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - 52s 166ms/step - loss: 1.5596\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - 52s 166ms/step - loss: 1.4019\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - 52s 167ms/step - loss: 1.3191\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - 52s 167ms/step - loss: 1.2679\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.2325\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - 52s 165ms/step - loss: 1.2051\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - 52s 167ms/step - loss: 1.1828\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - 53s 169ms/step - loss: 1.1638\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.1471\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.1318\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.1173\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.1037\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.0910\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - 52s 167ms/step - loss: 1.0790\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.0675\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.0564\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - 52s 167ms/step - loss: 1.0460\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.0359\n",
      "Epoch 21/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.0266\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.0174\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.0091\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 1.0010\n",
      "Epoch 25/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9937\n",
      "Epoch 26/40\n",
      "312/312 [==============================] - 52s 167ms/step - loss: 0.9870\n",
      "Epoch 27/40\n",
      "312/312 [==============================] - 52s 167ms/step - loss: 0.9805\n",
      "Epoch 28/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9752\n",
      "Epoch 29/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9698\n",
      "Epoch 30/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9652\n",
      "Epoch 31/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9608\n",
      "Epoch 32/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9572\n",
      "Epoch 33/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9535\n",
      "Epoch 34/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9504\n",
      "Epoch 35/40\n",
      "312/312 [==============================] - 52s 167ms/step - loss: 0.9474\n",
      "Epoch 36/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9443\n",
      "Epoch 37/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9434\n",
      "Epoch 38/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9411\n",
      "Epoch 39/40\n",
      "312/312 [==============================] - 52s 168ms/step - loss: 0.9398\n",
      "Epoch 40/40\n",
      "312/312 [==============================] - 53s 170ms/step - loss: 0.9376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19a0c89bb08>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 40\n",
    "model.fit(dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 64)             5376      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 84)             86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model.load_weights('shakespeare_gen.h5')\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take in a mode, start_seed, gensize, and temp\n",
    "# take the string, put it in index location, format and put in model, reset the model\n",
    "\n",
    "def generate_text(model, start_seed, gen_size=500, temp=0.1):\n",
    "    num_generate = gen_size\n",
    "    input_eval = [char_to_ind[s] for s in start_seed]\n",
    "    input_eval = tf.expand_dims(input_eval,0)\n",
    "    text_generated = []\n",
    "    temperature = temp\n",
    "    model.reset_states()\n",
    "    \n",
    "# for each of the characters, we will get a prediction, squeeze to undo the dimension and grab them,\n",
    "# What is the probability for each character, \n",
    "# get a single index digit as numpy, then start appending the text - join all together\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(ind_to_char[predicted_id])\n",
    "        \n",
    "    return (start_seed+\"\".join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIETHET. And I will with your honour and your son,\n",
      "    The which he loves me well; and that is mine\n",
      "    When I shall see thee here in passion with thee.\n",
      "    I say the truth is stol'n away the fool,\n",
      "    And that the noble Marcus Diomed,\n",
      "    And with the hand of mine hath sent to you\n",
      "    Where they shall have a sport in this world cannot be thus complete me\n",
      "    To be a sign of love and love and war.\n",
      "  PETRUCHIO. Why, this is here at hand, I say.\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"JULIET\", gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
